[2024-07-09T17:09:20.928+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: pesquisa_industrial_anual_empresas.workspace manual__2024-07-09T17:09:19.213006+00:00 [queued]>
[2024-07-09T17:09:20.936+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: pesquisa_industrial_anual_empresas.workspace manual__2024-07-09T17:09:19.213006+00:00 [queued]>
[2024-07-09T17:09:20.937+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-07-09T17:09:20.948+0000] {taskinstance.py:2217} INFO - Executing <Task(PapermillOperator): workspace> on 2024-07-09 17:09:19.213006+00:00
[2024-07-09T17:09:20.953+0000] {standard_task_runner.py:60} INFO - Started process 210 to run task
[2024-07-09T17:09:20.955+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'pesquisa_industrial_anual_empresas', 'workspace', 'manual__2024-07-09T17:09:19.213006+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/pesquisa_industrial_anual_empresas/dags.py', '--cfg-path', '/tmp/tmpkrxa1602']
[2024-07-09T17:09:20.958+0000] {standard_task_runner.py:88} INFO - Job 2: Subtask workspace
[2024-07-09T17:09:21.013+0000] {task_command.py:423} INFO - Running <TaskInstance: pesquisa_industrial_anual_empresas.workspace manual__2024-07-09T17:09:19.213006+00:00 [running]> on host 12f3c63a9469
[2024-07-09T17:09:21.088+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='observatorio@sistemafiea.com.br' AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='pesquisa_industrial_anual_empresas' AIRFLOW_CTX_TASK_ID='workspace' AIRFLOW_CTX_EXECUTION_DATE='2024-07-09T17:09:19.213006+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-07-09T17:09:19.213006+00:00'
[2024-07-09T17:09:21.090+0000] {execute.py:83} INFO - Input Notebook:  /opt/***/dags/pesquisa_industrial_anual_empresas/notebooks/workspace.ipynb
[2024-07-09T17:09:21.091+0000] {execute.py:84} INFO - Output Notebook: /opt/***/dags/resultado/pesquisa_industrial_anual_empresas_workspace_2024-07-09.ipynb
[2024-07-09T17:09:22.319+0000] {clientwrap.py:44} INFO - Executing notebook with kernel: python3
[2024-07-09T17:09:22.858+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/papermill/operators/papermill.py", line 118, in execute
    pm.execute_notebook(
  File "/home/airflow/.local/lib/python3.11/site-packages/papermill/execute.py", line 131, in execute_notebook
    raise_for_execution_errors(nb, output_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/papermill/execute.py", line 251, in raise_for_execution_errors
    raise error
papermill.exceptions.PapermillExecutionError: 
---------------------------------------------------------------------------
Exception encountered at "In [4]":
---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
Cell In[4], line 5
      1 # url para o cojunto de dados 
      2 url = "https://servicodados.ibge.gov.br/api/v3/agregados/1839/periodos/2022/variaveis/630?localidades=N1[all]"
----> 5 from pyspark.sql import SparkSession
      7 # Inicie uma sessão Spark
      8 spark = SparkSession.builder \
      9     .appName("Pesquisa Industrial Anual - Empresas") \
     10     .getOrCreate()

ModuleNotFoundError: No module named 'pyspark'

[2024-07-09T17:09:22.868+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=pesquisa_industrial_anual_empresas, task_id=workspace, execution_date=20240709T170919, start_date=20240709T170920, end_date=20240709T170922
[2024-07-09T17:09:22.898+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 2 for task workspace (
---------------------------------------------------------------------------
Exception encountered at "In [4]":
---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
Cell In[4], line 5
      1 # url para o cojunto de dados 
      2 url = "https://servicodados.ibge.gov.br/api/v3/agregados/1839/periodos/2022/variaveis/630?localidades=N1[all]"
----> 5 from pyspark.sql import SparkSession
      7 # Inicie uma sessão Spark
      8 spark = SparkSession.builder \
      9     .appName("Pesquisa Industrial Anual - Empresas") \
     10     .getOrCreate()

ModuleNotFoundError: No module named 'pyspark'
; 210)
[2024-07-09T17:09:22.938+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-07-09T17:09:22.952+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
