x-airflow-common: &airflow-common
  image: local-cluster-airflow:1.0.0
  environment: &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'

    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
    
    # configure as chaves abaixo
    AIRFLOW__CORE__FERNET_KEY: '2gKTL2Dnq9IDd_mg9E4kZ8ECtSV5YWEB3tHycj9gPgo='
    AIRFLOW__WEBSERVER__SECRET_KEY: 'aff8f98bfce165f856ffe201435e1e737ef694498e68620e'

    AIRFLOW_UID: 197609

  volumes: &airflow-common-volumes
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins

  user: "${AIRFLOW_UID:-197609}:0"

  depends_on: &airflow-common-depends-on
    postgres:
      condition: service_healthy

services:
  postgres:
    image: postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    healthcheck:
      test: [ "CMD", "pg_isready", "-p", "5432", "-U", "airflow" ]
      interval: 5s
      retries: 5

  spark:
    image: bitnami/spark:latest
    ports:
      - 4040:4040
    volumes:
      - ./spark-app:/app
    environment:
      - SPARK_MODE=master
    
  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - 11000:8080
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully
  
  airflow-init:
    <<: *airflow-common
    entrypoint: /bin/bash
    # yamllint enable rule:line-length
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}
      _PIP_ADDITIONAL_REQUIREMENTS: ''
    command:
      - -c
      - |
        mkdir -p /sources/logs /sources/dags /sources/plugins
        chown -R "${AIRFLOW_UID}:0" /sources/{logs,dags,plugins}
        exec /entrypoint airflow version
    user: "0:0"
    volumes:
      - .:/sources